{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_rXJKL8UctF",
        "outputId": "0405bcfb-fd07-45b2-a0c2-96cacd426e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg4slB2Xb5k_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import replicate\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2JupIctYZwM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/WELFake_Dataset.csv', nrows=478, on_bad_lines='skip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5pc06f2doV0"
      },
      "outputs": [],
      "source": [
        "# multiple shots shot\n",
        "def create_prompt(article_text):\n",
        "    prompt = f\"\"\"\n",
        "    The following are clues to detect whether news articles are \"real\" or \"fake.\"\n",
        "    Articles related to politics ( mainly in USA and middle eastern and asian countries) or national security and defence or terrorism or climate change and those coming from Reuters have higher chance to be fake.\n",
        "    Articles that cite reputable sources and have image and video evidence in them, are more likely to be real.\n",
        "\n",
        "    Now Classify the given article as either \"real\" or \"fake.\" :\n",
        "    Article: \"{article_text}\"\n",
        "    Label:\n",
        "    \"\"\"\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6NeDAbIXTfD"
      },
      "outputs": [],
      "source": [
        "client = replicate.Client(api_token=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "bseUZJo5XySy",
        "outputId": "521b5b65-f859-468f-c99a-ebaf92fa38cc"
      },
      "outputs": [
        {
          "ename": "ReplicateError",
          "evalue": "ReplicateError Details:\ntitle: Monthly spend limit reached\nstatus: 402\ndetail: You've hit your monthly spend limit. You can change or remove your limit at https://replicate.com/account/billing#limits.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReplicateError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-081d5806c55b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Call the model for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     result = client.run(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;34m\"ibm-granite/granite-3.0-8b-instruct\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         input={\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, ref, input, use_file_output, **params)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \"\"\"\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_file_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_file_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     async def async_run(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/replicate/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(client, ref, input, use_file_output, **params)\u001b[0m\n\u001b[1;32m     48\u001b[0m         )\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mowner\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         prediction = client.models.predictions.create(\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/replicate/model.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, input, **params)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_prediction_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mextras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_prediction_request_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_json_to_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mReplicateError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mReplicateError\u001b[0m: ReplicateError Details:\ntitle: Monthly spend limit reached\nstatus: 402\ndetail: You've hit your monthly spend limit. You can change or remove your limit at https://replicate.com/account/billing#limits."
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "\n",
        "# Iterate over the 500 examples\n",
        "for index, row in df.iterrows():\n",
        "    article = row['text']  # assuming the text column is named 'text'\n",
        "    prompt = create_prompt(article)\n",
        "\n",
        "    # Call the model for prediction\n",
        "    result = client.run(\n",
        "        \"ibm-granite/granite-3.0-8b-instruct\",\n",
        "        input={\n",
        "        \"top_k\": 10,\n",
        "        \"prompt\": prompt,\n",
        "        \"max_tokens\": 10,\n",
        "        \"min_tokens\": 1,\n",
        "        \"temperature\": 0,\n",
        "        \"system_prompt\": \"You are an expert in fake news detection and your job is to classify articles into fake or real news. Only answer with 'Real' or 'Fake'\",\n",
        "        \"repetition_penalty\": 1,\n",
        "        \"presence_penalty\": 0,\n",
        "        \"frequency_penalty\": 0\n",
        "    },\n",
        "    )\n",
        "\n",
        "    # Assuming the result is a string with 'Real' or 'Fake' as output\n",
        "    predictions.append(result[-1].strip())  # Clean the result (strip spaces)\n",
        "\n",
        "    # Introduce a delay of 1 second between requests\n",
        "    time.sleep(0.5)\n",
        "      # You can adjust the sleep time (in seconds) as needed\n",
        "\n",
        "print(predictions[:5])  # Print first 5 predictions to check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbS171D5aCqU",
        "outputId": "c5b4f9ca-56f6-450e-f6c8-c42a4cf5c881"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " ', but I need',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'The article',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'is a',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " '',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'current state',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'confusion, but I need',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'label for this',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'discusses',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'because it',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Fake',\n",
              " \"' because it\",\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'guard',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'is from',\n",
              " 'It provides',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '\" because it',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '. It contains',\n",
              " '',\n",
              " '',\n",
              " 'The article',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " '',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'the',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '',\n",
              " 'it',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'it',\n",
              " '',\n",
              " 'Real',\n",
              " '',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'confusion, but I need',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Real',\n",
              " 'likely fake due to its',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " '\" because it',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'confusion, but I need',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'It contains',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'because it',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'It contains',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'article',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " '',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " '',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real',\n",
              " '',\n",
              " 'Real',\n",
              " 'Fake',\n",
              " 'Real',\n",
              " 'Real']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVhq1TrniGkK",
        "outputId": "ee6ce8fc-47fb-40e1-c725-c9c9654983c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "478"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJfwOxm6ikPI",
        "outputId": "2ec34de1-a638-42d4-ecd0-bb7a68009105"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "478"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_labels = ['Real' if 'Real' in label else 'Fake' if 'Fake' in label else 'Fake' for label in predictions]\n",
        "\n",
        "len(filtered_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7_y3ANcX2gx",
        "outputId": "5ad3b94a-5c05-4ed1-ccf3-876babc23a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 23.64%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming 'label' column contains the true labels\n",
        "true_labels = df['label'].replace({1: 'Real', 0: 'Fake'}).values  # Replace with the actual column name for true labels\n",
        "#true_labels = true_labels[:500]\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, filtered_labels)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUSY0PILkX8S"
      },
      "outputs": [],
      "source": [
        "full_predictions = ['Real' if 'Real' in label else 'Fake' if 'Fake' in label else None for label in predictions]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59AJuH9hkeJJ"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'True Labels': true_labels, 'Predictions': full_predictions})\n",
        "\n",
        "# Remove rows where any column is None (or NaN)\n",
        "df_cleaned = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOuNqIsokj0o",
        "outputId": "f37eeea1-66de-46fc-c911-a584647b1539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 21.14%\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(df_cleaned['True Labels'], df_cleaned['Predictions'])\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
